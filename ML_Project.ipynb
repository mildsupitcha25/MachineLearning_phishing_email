{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mildsupitcha25/MachineLearning_phishing_email/blob/main/ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwGc0lweXhiY",
        "outputId": "03aea71e-47ca-40ec-94fa-e9065e7d179b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "กำลังฝึก XGBoost บนข้อมูล 100 ตัวอย่าง...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [14:09:19] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ฝึกโมเดลเสร็จสิ้น\n",
            "\n",
            "==================================================\n",
            "✨ ผลลัพธ์การประเมินโมเดล XGBoost บนชุดทดสอบ 20% ✨\n",
            "==================================================\n",
            "Accuracy: 0.6923 (งานวิจัยทำได้ 0.96) [cite: 576]\n",
            "Precision: 0.6667 (งานวิจัยทำได้ 0.96) [cite: 601]\n",
            "Recall: 0.7692 (งานวิจัยทำได้ 0.96) [cite: 601]\n",
            "F1-Score: 0.7143 (งานวิจัยทำได้ 0.96) [cite: 601]\n",
            "AUC-Score: 0.7515 (งานวิจัยทำได้ 0.99) [cite: 601]\n",
            "\n",
            "--- Confusion Matrix ---\n",
            "True Negatives (TN): 8\n",
            "False Positives (FP): 5\n",
            "False Negatives (FN): 3\n",
            "True Positives (TP): 10\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import xgboost as xgb\n",
        "\n",
        "## --- 1. การสร้างข้อมูลจำลอง (Simulated Stylometric Data) ---\n",
        "# ในสถานการณ์จริง คุณจะต้องใช้ข้อมูล stylometric 60 ฟีเจอร์ที่สกัดจากอีเมล\n",
        "# เช่น imperative_verbs_count, clause_density, first_person_pronoun_count\n",
        "# โดยมีจำนวนตัวอย่างทั้งหมด 126 อีเมล (63 Phishing, 63 Legitimate)\n",
        "\n",
        "n_samples = 126 # จำนวนตัวอย่างทั้งหมดในงานวิจัย (63 Phishing + 63 Legitimate) [cite: 143]\n",
        "n_features = 60 # จำนวน Stylometric Features ที่ใช้ [cite: 304, 316]\n",
        "\n",
        "# สร้าง DataFrame จำลอง (สมมติว่า 'X' คือ 60 ฟีเจอร์ที่ผ่านการสกัดแล้ว)\n",
        "# สร้างข้อมูลที่มีความแตกต่างกันเล็กน้อยระหว่าง 2 Class เพื่อให้โมเดลสามารถเรียนรู้ได้\n",
        "X = np.random.rand(n_samples, n_features) * 5\n",
        "y = np.array([0] * (n_samples // 2) + [1] * (n_samples - n_samples // 2)) # 0: Legitimate, 1: Phishing\n",
        "\n",
        "# ปรับให้ข้อมูล Phishing (y=1) มีค่าในฟีเจอร์สำคัญสูงขึ้นเล็กน้อย\n",
        "# (เช่น ฟีเจอร์ 0 สมมติเป็น imperative_verbs_count)\n",
        "X[y == 1, 0] = X[y == 1, 0] + 1.5\n",
        "# (ฟีเจอร์ 1 สมมติเป็น clause_density)\n",
        "X[y == 1, 1] = X[y == 1, 1] + 1.0\n",
        "\n",
        "\n",
        "## --- 2. การเตรียมข้อมูล (Data Preprocessing) ---\n",
        "\n",
        "# 2.1. การปรับมาตรฐาน (Feature Scaling)\n",
        "# StandardScaler จะแปลงข้อมูลให้มีค่าเฉลี่ยเป็น 0 และส่วนเบี่ยงเบนมาตรฐานเป็น 1\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 2.2. การแบ่งชุดข้อมูล (Train-Test Split)\n",
        "# แบ่งเป็น Training 80% และ Testing 20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.20, random_state=42, stratify=y)\n",
        "# stratify=y ช่วยให้สัดส่วนของ Phishing/Legitimate ในชุด Train/Test ใกล้เคียงกัน\n",
        "\n",
        "\n",
        "## --- 3. การฝึกโมเดล XGBoost (XGBoost Model Training) ---\n",
        "\n",
        "# 3.1. กำหนดค่า Hyperparameters\n",
        "# ใช้ค่าเริ่มต้นจาก Scikit-learn และตามที่งานวิจัยระบุ (eval_metric='logloss', random_state=42)\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 3.2. ฝึกโมเดล\n",
        "print(f\"กำลังฝึก XGBoost บนข้อมูล {len(X_train)} ตัวอย่าง...\")\n",
        "xgb_model.fit(X_train, y_train)\n",
        "print(\"ฝึกโมเดลเสร็จสิ้น\")\n",
        "\n",
        "\n",
        "## --- 4. การประเมินผล (Model Evaluation) ---\n",
        "\n",
        "# 4.1. การทำนาย (Prediction)\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1] # สำหรับคำนวณ AUC\n",
        "\n",
        "# 4.2. คำนวณเมตริกการประเมินผล\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel() # ดึงค่าจาก Confusion Matrix\n",
        "\n",
        "# 4.3. แสดงผลลัพธ์\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"✨ ผลลัพธ์การประเมินโมเดล XGBoost บนชุดทดสอบ 20% ✨\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Accuracy: {accuracy:.4f} (งานวิจัยทำได้ 0.96) [cite: 576]\")\n",
        "print(f\"Precision: {precision:.4f} (งานวิจัยทำได้ 0.96) [cite: 601]\")\n",
        "print(f\"Recall: {recall:.4f} (งานวิจัยทำได้ 0.96) [cite: 601]\")\n",
        "print(f\"F1-Score: {f1:.4f} (งานวิจัยทำได้ 0.96) [cite: 601]\")\n",
        "print(f\"AUC-Score: {auc_score:.4f} (งานวิจัยทำได้ 0.99) [cite: 601]\")\n",
        "\n",
        "print(\"\\n--- Confusion Matrix ---\")\n",
        "print(f\"True Negatives (TN): {tn}\") # Legitimate ถูกทำนายถูก\n",
        "print(f\"False Positives (FP): {fp}\") # Legitimate ถูกทำนายผิดเป็น Phishing\n",
        "print(f\"False Negatives (FN): {fn}\") # Phishing ถูกทำนายผิดเป็น Legitimate\n",
        "print(f\"True Positives (TP): {tp}\") # Phishing ถูกทำนายถูก [cite: 575]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "# กำหนดชื่อไฟล์ CSV ของคุณ\n",
        "CSV_FILE = 'stylometric_features.csv'\n",
        "\n",
        "# 2.1. โหลดข้อมูล\n",
        "try:\n",
        "    data = pd.read_csv(CSV_FILE)\n",
        "    print(f\"โหลดข้อมูลจาก {CSV_FILE} สำเร็จ. ขนาดข้อมูล: {data.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"เกิดข้อผิดพลาด: ไม่พบไฟล์ {CSV_FILE} โปรดตรวจสอบชื่อไฟล์\")\n",
        "    exit()\n",
        "\n",
        "# 2.2. แยกฟีเจอร์ (X) และป้ายกำกับ (y)\n",
        "# 'Label' คือชื่อคอลัมน์ของผลลัพธ์ (เป้าหมาย)\n",
        "X = data.drop('Label', axis=1)\n",
        "y = data['Label']\n",
        "\n",
        "# 2.3. การปรับมาตรฐาน (Feature Scaling)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns) # แปลงกลับเป็น DataFrame เพื่อให้จัดการง่าย\n",
        "\n",
        "# 2.4. การแบ่งชุดข้อมูล (Train-Test Split)\n",
        "# แบ่งเป็น Training 80% และ Testing 20%\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.20, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"ขนาดชุดฝึก (Train Set): {len(X_train)} ตัวอย่าง\")\n",
        "print(f\"ขนาดชุดทดสอบ (Test Set): {len(X_test)} ตัวอย่าง\")\n",
        "\n",
        "# --- 3. การฝึกโมเดล CatBoost และการประเมินผล ---\n",
        "\n",
        "# 3.1. กำหนดค่า Hyperparameters\n",
        "cb_model = CatBoostClassifier(\n",
        "    iterations=100,\n",
        "    loss_function='Logloss',\n",
        "    random_state=42,\n",
        "    verbose=0,\n",
        "    early_stopping_rounds=10\n",
        ")\n",
        "\n",
        "# 3.2. ฝึกโมเดล\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"กำลังฝึก CatBoost Model...\")\n",
        "cb_model.fit(X_train, y_train)\n",
        "print(\"ฝึกโมเดลเสร็จสิ้น\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 3.3. การประเมินผล\n",
        "y_pred = cb_model.predict(X_test)\n",
        "y_pred_proba = cb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# คำนวณเมตริก\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "# 3.4. แสดงผลลัพธ์\n",
        "print(\"✨ ผลลัพธ์การประเมินโมเดล CatBoost บนชุดทดสอบ 20% ✨\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"AUC-Score: {auc_score:.4f}\")\n",
        "\n",
        "print(\"\\n--- Confusion Matrix ---\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"True Positives (TP): {tp}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "YQmfeg-lYmwA",
        "outputId": "33518a0e-409f-43b4-f6cb-0efba9744e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'catboost'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1602171188.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. การสร้างข้อมูลจำลอง (Simulated Data) ---\n",
        "# ในสถานการณ์จริง คุณจะโหลดข้อมูลอีเมลของคุณเอง\n",
        "data = {\n",
        "    'text': [\n",
        "        \"Congratulations! You've won a free iPhone. Click here now.\",\n",
        "        \"Meeting agenda attached, please review before tomorrow's session.\",\n",
        "        \"URGENT: Your account has been suspended. Verify your details immediately.\",\n",
        "        \"Can we reschedule our lunch meeting to next week?\",\n",
        "        \"Viagra and Cialis at discount prices! Limited stock.\",\n",
        "        \"Your order #1001 has been shipped and is on its way.\",\n",
        "        \"Hello, this is a test email for spam filtering.\",\n",
        "        \"Claim your prize money! Send us your bank details fast.\",\n",
        "        \"Don't miss out on this exclusive offer, 50% off everything!\",\n",
        "        \"Regarding the project proposal, I've made some revisions.\"\n",
        "    ],\n",
        "    'label': [\n",
        "        'spam', 'ham', 'spam', 'ham', 'spam',\n",
        "        'ham', 'ham', 'spam', 'spam', 'ham'\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# แปลง Label ให้อยู่ในรูปตัวเลข (0=ham, 1=spam)\n",
        "df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "X = df['text']\n",
        "y = df['label_num']\n",
        "\n",
        "\n",
        "# --- 2. การแบ่งข้อมูล (Train-Test Split) ---\n",
        "# แบ่งข้อมูลเป็นชุดฝึก (Training) และชุดทดสอบ (Testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "# stratify=y ช่วยรักษาสัดส่วน spam/ham ในชุดข้อมูล\n",
        "\n",
        "\n",
        "# --- 3. การสร้างคุณลักษณะ (Feature Engineering: TF-IDF) ---\n",
        "\n",
        "# TfidfVectorizer แปลงข้อความให้เป็นเวกเตอร์ของตัวเลข โดยให้น้ำหนักคำที่สำคัญ\n",
        "vectorizer = TfidfVectorizer(stop_words='english', lowercase=True)\n",
        "\n",
        "# ฝึก Vectorizer ด้วยข้อมูลชุดฝึก และแปลงชุดฝึก\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# แปลงชุดทดสอบ (ใช้ fit ที่ฝึกจากชุดฝึกเท่านั้น เพื่อป้องกัน Data Leakage)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "# --- 4. การฝึกโมเดล (Model Training: Multinomial Naïve Bayes) ---\n",
        "\n",
        "# MultinomialNB เหมาะสำหรับคุณลักษณะที่เป็นการนับ (Count) หรือความถี่ (Frequency)\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# ฝึกโมเดล\n",
        "nb_model.fit(X_train_vec, y_train)\n",
        "\n",
        "\n",
        "# --- 5. การประเมินผล (Model Evaluation) ---\n",
        "\n",
        "# ทำนายผลบนชุดทดสอบ\n",
        "y_pred = nb_model.predict(X_test_vec)\n",
        "\n",
        "# คำนวณความแม่นยำและเมตริกอื่น ๆ\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred, target_names=['Ham (0)', 'Spam (1)'])\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"✨ ผลลัพธ์การจำแนก Spam/Ham ด้วย Naïve Bayes ✨\")\n",
        "print(\"=\"*50)\n",
        "print(f\"ความแม่นยำ (Accuracy): {accuracy:.4f}\")\n",
        "print(\"\\n--- Confusion Matrix ---\")\n",
        "print(conf_matrix)\n",
        "print(\"\\n--- Classification Report ---\")\n",
        "print(class_report)\n",
        "\n",
        "# --- 6. การทดสอบกับอีเมลใหม่ (New Prediction) ---\n",
        "new_email = [\"Verify your account password now or it will be deleted.\",\n",
        "             \"Just checking in on the report status, no rush.\"]\n",
        "new_email_vec = vectorizer.transform(new_email)\n",
        "new_pred = nb_model.predict(new_email_vec)\n",
        "\n",
        "print(\"\\n--- การทำนายอีเมลใหม่ ---\")\n",
        "for i, pred in enumerate(new_pred):\n",
        "    label = 'SPAM' if pred == 1 else 'HAM'\n",
        "    print(f\"อีเมล: '{new_email[i]}' -> ทำนายเป็น: {label}\")"
      ],
      "metadata": {
        "id": "8btCrvQjadxt",
        "outputId": "4f950f86-5afd-465e-ed46-2f0c2df3a544",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "✨ ผลลัพธ์การจำแนก Spam/Ham ด้วย Naïve Bayes ✨\n",
            "==================================================\n",
            "ความแม่นยำ (Accuracy): 0.6667\n",
            "\n",
            "--- Confusion Matrix ---\n",
            "[[1 1]\n",
            " [0 1]]\n",
            "\n",
            "--- Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Ham (0)       1.00      0.50      0.67         2\n",
            "    Spam (1)       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.75      0.75      0.67         3\n",
            "weighted avg       0.83      0.67      0.67         3\n",
            "\n",
            "\n",
            "--- การทำนายอีเมลใหม่ ---\n",
            "อีเมล: 'Verify your account password now or it will be deleted.' -> ทำนายเป็น: SPAM\n",
            "อีเมล: 'Just checking in on the report status, no rush.' -> ทำนายเป็น: SPAM\n"
          ]
        }
      ]
    }
  ]
}